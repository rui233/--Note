一、特征工程

1、为什么要进行特征归一化

为了消除特征之间的量纲影响，使得不同指标之间具有可比性。

2、特征归一化的方法

线性函数归一化
$$
x_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}
$$
零均值归一化
$$
z = \frac{x-\mu}{\sigma}
$$
3、再对数据进行预处理时，应该怎么处理类别型特征？

序号编码(Ordinal Encoding)：对于类别之间有大小关系的数据，采用序号编码的形式按照大小关系对类别特征赋予一个数值ID

独热编码（One-Hot Encoding): 用于类别间不具有大小关系的数据；当类别取值较多时需要注意使用稀疏向量以及配合特征选择来降低维度

二进制编码（Binary Encoding): 本质上利用二进制对ID进行哈希映射，得到0/1特征向量，且维数小于独热编码，节省空间

4、什么是组合特征？

为了提高复杂关系的拟合能力，在特征工程中会经常对一阶离散特征两两组合，构成高阶组合特征

5、如何处理高维组合特征？

降低维度，比如推荐系统中的矩阵分解，将m x m 的参数表示为m x k + n x k

6、怎么有效地找到组合特征？

比如基于决策树的特征组合寻找方法，采用梯度上升决策树，该方法的思想是每次在之前构建的决策树的残差上构建下一颗决策树。

注： GBDT 可以发现具有区分度的特征以及特征组合

7、图像数据不足带来的问题？如何缓解？

过拟合，模型在训练样本上变现不错，在测试样本上泛化效果不好。

基于模型的方法和数据增广



基于模型的方法:

简化模型、添加约束项（正则项）、集成学习、Dropout超参数等



数据增广：

随机旋转、平移、缩放、裁剪、填充、左右翻转

颜色变换

添加噪声扰动：椒盐噪声、高斯白噪声

改变亮度、对比度、锐度、清晰度



二、评价指标

1、基本指标

准确率（accuracy) 
$$
accuracy =\frac{(TP +TN)}{P+N}
$$

错误率（error rate)
$$
error \quad rate = \frac{(FP+FN)}{P+N}
$$
灵敏度（sensitivity):                    所有正例中被分对的概率,衡量分类器对正例的识别能力


$$
sensitity = \frac{TP}{P}
$$
特异性（specificity)   :                  所有负例中被分对的概率，衡量分类器对负例的识别能力


$$
specificity = \frac{TN}{N}
$$
精度（precision):                         所有预测为类别C的样本中预测正确的比例
$$
P_c = \frac{TP_c}{TP_c+FP_c}
$$
召回率（Recall）：                    所有真实标签为类别c的样本中，预测正确的比率
$$
R_c = \frac{TP_c}{TP_c+FN_c}
$$
F值（F Method):                           为精度和召回率的调和平均,beta值为权重值，一般为1，此时称为F1值
$$
F_c=\frac{(1+\beta^2)*P_c*R_c}{\beta^2*P_c+R_c}
$$
ROC（Receiver operating Characteristic Curve)受试者工作特征曲线，以（1-特异性）为横坐标，灵敏度为纵坐标绘制的性能评价曲线。可以把不同模型对同一个数据集的ROC曲线绘制在同一个笛卡尔坐标系中，ROC曲线越靠近左上方，说明模型越可靠。ROC下方的面积（Area Under Curve)AUC也可用来评价模型，AUC越大，模型越可靠。



PR（Precision Recall Curve),Recall为横坐标，precision为纵坐标，其对应的AUC为目标检测当中常用的评价指标平均精度（AP,Average Precision),AP越高，模型越好。



准确率（Accuracy)的局限性：当不同类别的样本比例非常不均衡时，占比大的类别成为了影响正确率最主要的因素，反映的是整体的准确率，不能代表细分类别的准确率



2、只用准确率能很好的评估分类算法吗？

不能，当数据分布不均衡，类别a的数据太少，错分了类别a但总体可以准确率很高，忽略了研究者最关注的类别a



3、ROC相比PR曲线有什么特点？

当正负样本分布发生变化时，ROC曲线形状基本保持不变，PR曲线一般会发生比较剧烈的变化；因此ROC曲线可以尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能，因此ROC使用场景更广；而PR曲线能更直观地反映模型在特定数据集上的性能



4、过拟合与欠拟合分别指什么？

过拟合指的对于训练数据拟合过当，模型在训练集上表现很好，在测试集上表现较差

欠拟合指的模型在训练数据和测试数据上表现都不好



5、降低过拟合和欠拟合风险的方法？

降低过拟合风险的方法：

使用更多的训练数据

降低模型复杂度

正则化方法

集成学习方法



降低欠拟合风险的方法：

添加新特征

增加模型复杂度

减小正则化系数



6、超参数的调优方法

网格搜索、随机搜索、贝叶斯优化

网格搜索：查找搜索范围内的所有点来确定最优值，十分消耗计算资源和时间

随机搜索：在搜索范围内随机选取样本点，比网格搜索快，但结果无法保证

贝叶斯优化：通过对目标函数进行学习，寻找使目标函数向全局最优值提升的参数；但容易陷入局部最优值，用探索和利用来改进，探索指还未取样的区域，里利用指在最可能出现全局最值的地方进行采样



7、在模型评估的过程中，有哪些主要的验证方法，它们的优缺点

Holdout、交叉验证、自助法

Holdout:将原始样本随机划分成训练集和测试集两部分，缺点是测试集上计算出来的最后评估指标和原始分组有很大关系，优点是简单

交叉验证：K-fold交叉验证、留一验证

K-fold交叉验证：将全部样本划分为k个大小相等的样本子集，依次遍历这k个子集，每次把当前子集作为验证集，其余所有子集为训练集，最后把k次评估指标的平均值作为最终的评估指标。k经常取10

留一验证：

每次留下一个样本作为验证集，其他是测试集，当样本总数很多的时候，时间开销极大

自助法：

自主采样法，对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集，将那些没有被抽出的样本作为验证集，进行模型验证。



8、如何进行线上A\B测试？

将用户分为实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型。分桶过程中，注意样本的独立性和采样方式的无偏性，来确保同一个用户每次只能分到同一个桶中



9、在对模型经过充分的离线评估之后，为什么还要进行在线A\B测试？

离线评估无法完全还原线上的工程环境

线上系统的某些指标在离线评估中无法计算

离线评估无法完全消除模型过拟合的影响



10、余弦距离是不是一个严格定义的距离？

不是，距离的定义需要满足正定性、对称性和三角不等式，余弦距离不满足三角不等式，举反例可证明



